name: mini-only-stackexchange # Name of the sweep - it'll be used in run names
project: mosaic-gpt2  # Name of the Weights and Biases project to use
image: davhall/codalab-composer:latest # #mosaicml/pytorch  # Name of the docker image to use
git_repo: https://github.com/stanford-crfm/composer  # Name of the git repo to clone - can be full URL or path under github.com
git_branch: multinode_gpt2  # Name of the git branch/tag/commit to use
# The below will -
# 1. Clone the git repo (which is filled in automatically)
# 2. Checkout the correct branch (Also filled in automatically)
# 3. Do a local pip install
# 4. Run composer using a full parameters config file, mounted to /mnt/config/parameters.yaml
command: |
  git clone {{ git_repo }} $HOME/composer
  cd $HOME/composer
  echo 'Checking out composer branch {{ git_branch }}'
  git checkout {{ git_branch }}
  pip install --user -e .[all]
  export PATH=$PATH:$HOME/.local/bin
  composer -n 8 examples/run_composer_trainer.py -f /mnt/config/parameters.yaml --run_name {{ name }}
instance: r6z1-g8-a100  # Name of the instance you want to run on, e.g. r6z1-g8-a100
models: mistral_weighted_gpt2_11m  # The name of the model you want to use - should match the name of a YAML file in your local composer "models" directory unless you are fully specifying model parameters in the `parameters` section
algorithms: []# The name(s) of the algorithm(s) you want to use - should match the name of a YAML file in your local composer "algorithms" directory unless you are fully specifying algorithms parameters in the `parameters` section
parameters:  # Any parameter overrides you want to use IN EVERY RUN should be specified here
  ##############################
  # Saving model checkpoints to WandB
  save_folder: "/tmp/{run_name}"
  save_artifact_name: "{run_name}/checkpoints/rank{rank}"
  save_interval: 20000ba
  save_num_checkpoints_to_keep: 1
  callbacks:
    - lr_monitor: {}
    - loss_scale_monitor: { }
    - grad_monitor:
        log_layer_grad_norms: true
    - lr_monitor: { }
    - speed_monitor:
        window_size: 10
  loggers:
    - wandb:
        log_artifacts: true
        entity: stanford-mercury
        project: mosaic-gpt2
  ##############################
  seed: 1
  train_dataset:
    sprucfluo:
      weights:
        pubmedAbs: 0
        pubmedC: 0
        medical: 0
        nih: 0
        wikipedia: 0
        books: 0
        academic: 0
        hackernews: 0
        subtitles: 0
        stack_exchange: 1
        ubuntu_irc: 0
        webtext: 0
        law: 0
        enron: 0
        europarl: 0
        gutenberg: 0
        uspto: 0
