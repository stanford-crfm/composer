# Configuration to launch a job with mcli
#
# Usage:
# mcli sweep -f mistral_medical_gpt2.yaml
#
# Supported:
#    mistral_medical_gpt2_125m.yaml
#    mistral_medical_gpt2_350m.yaml

name: mistral-medical-gpt2-11m-finetuned # Name of the sweep - it'll be used in run names
project: mosaic-gpt2  # Name of the Weights and Biases project to use
image: mosaicml/pytorch  # Name of the docker image to use
git_repo: https://github.com/stanford-crfm/composer  # Name of the git repo to clone - can be full URL or path under github.com
git_branch: pubmed  # Name of the git branch/tag/commit to use
# The below will -
# 1. Clone the git repo (which is filled in automatically)
# 2. Checkout the correct branch (Also filled in automatically)
# 3. Do a local pip install
# 4. Run composer using a full parameters config file, mounted to /mnt/config/parameters.yaml
command: |
  git clone {{ git_repo }} $HOME/composer
  cd $HOME/composer
  echo 'Checking out composer branch {{ git_branch }}'
  git checkout {{ git_branch }}
  pip install --user -e .[all]
  composer -n {{ parameters['_n_gpus'] }} examples/run_composer_trainer.py -f /mnt/config/parameters.yaml
instance: r6z1-g8-a100  # Name of the instance you want to run on, e.g. r6z1-g8-a100
models: mistral_medical_gpt2_11m  # The name of the model you want to use - should match the name of a YAML file in your local composer "models" directory unless you are fully specifying model parameters in the `parameters` section
algorithms: []# The name(s) of the algorithm(s) you want to use - should match the name of a YAML file in your local composer "algorithms" directory unless you are fully specifying algorithms parameters in the `parameters` section
parameters:  # Any parameter overrides you want to use IN EVERY RUN should be specified here
  ##############################
  # Saving model checkpoints to WandB
  save_folder: checkpoints
  save_interval: 20000ba
  loggers:
    - wandb:
        log_artifacts: true
        entity: stanford-mercury
        project: mosaic-gpt2
  ##############################
  callbacks:
    - lr_monitor: {}
    - speed_monitor:
        window_size: 10
  seed: 1
